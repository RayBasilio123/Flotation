{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'TabPFN'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/rayba/Music/mestrado_dados/vale-nova/codigo/TabPFN\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch<3,>=2.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.2.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (1.6.1)\n",
      "Requirement already satisfied: typing_extensions>=4.4.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (4.13.0)\n",
      "Requirement already satisfied: scipy<2,>=1.11.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (1.15.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (2.2.3)\n",
      "Requirement already satisfied: einops<0.9,>=0.2.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1,>=0.0.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (0.29.3)\n",
      "Collecting pre-commit (from tabpfn==2.0.7)\n",
      "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting ruff (from tabpfn==2.0.7)\n",
      "  Downloading ruff-0.11.2-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting mypy (from tabpfn==2.0.7)\n",
      "  Downloading mypy-1.15.0-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting pytest (from tabpfn==2.0.7)\n",
      "  Using cached pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting onnx (from tabpfn==2.0.7)\n",
      "  Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from tabpfn==2.0.7) (7.0.0)\n",
      "Collecting mkdocs (from tabpfn==2.0.7)\n",
      "  Downloading mkdocs-1.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting mkdocs-material (from tabpfn==2.0.7)\n",
      "  Downloading mkdocs_material-9.6.9-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting mkdocs-autorefs (from tabpfn==2.0.7)\n",
      "  Downloading mkdocs_autorefs-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mkdocs-gen-files (from tabpfn==2.0.7)\n",
      "  Downloading mkdocs_gen_files-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mkdocs-literate-nav (from tabpfn==2.0.7)\n",
      "  Downloading mkdocs_literate_nav-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting mkdocs-glightbox (from tabpfn==2.0.7)\n",
      "  Downloading mkdocs_glightbox-0.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting mkdocstrings[python] (from tabpfn==2.0.7)\n",
      "  Downloading mkdocstrings-0.29.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting markdown-exec[ansi] (from tabpfn==2.0.7)\n",
      "  Downloading markdown_exec-1.10.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting mike (from tabpfn==2.0.7)\n",
      "  Downloading mike-2.1.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting black (from tabpfn==2.0.7)\n",
      "  Downloading black-25.1.0-cp312-cp312-win_amd64.whl.metadata (81 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->tabpfn==2.0.7) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->tabpfn==2.0.7) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->tabpfn==2.0.7) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->tabpfn==2.0.7) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from scikit-learn<1.7,>=1.2.0->tabpfn==2.0.7) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from scikit-learn<1.7,>=1.2.0->tabpfn==2.0.7) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from torch<3,>=2.1->tabpfn==2.0.7) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from torch<3,>=2.1->tabpfn==2.0.7) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from torch<3,>=2.1->tabpfn==2.0.7) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from torch<3,>=2.1->tabpfn==2.0.7) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.1->tabpfn==2.0.7) (1.3.0)\n",
      "Collecting click>=8.0.0 (from black->tabpfn==2.0.7)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black->tabpfn==2.0.7)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from black->tabpfn==2.0.7)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from black->tabpfn==2.0.7) (4.3.7)\n",
      "Collecting pymdown-extensions>=9 (from markdown-exec[ansi]; extra == \"dev\"->tabpfn==2.0.7)\n",
      "  Downloading pymdown_extensions-10.14.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pygments-ansi-color>=0.3 (from markdown-exec[ansi]; extra == \"dev\"->tabpfn==2.0.7)\n",
      "  Downloading pygments_ansi_color-0.3.0-py3-none-any.whl.metadata (506 bytes)\n",
      "Collecting importlib-metadata (from mike->tabpfn==2.0.7)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting importlib-resources (from mike->tabpfn==2.0.7)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pyparsing>=3.0 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from mike->tabpfn==2.0.7) (3.2.3)\n",
      "Collecting pyyaml-env-tag (from mike->tabpfn==2.0.7)\n",
      "  Downloading pyyaml_env_tag-0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting verspec (from mike->tabpfn==2.0.7)\n",
      "  Downloading verspec-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from mkdocs->tabpfn==2.0.7) (0.4.6)\n",
      "Collecting ghp-import>=1.0 (from mkdocs->tabpfn==2.0.7)\n",
      "  Downloading ghp_import-2.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting markdown>=3.3.6 (from mkdocs->tabpfn==2.0.7)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from mkdocs->tabpfn==2.0.7) (3.0.2)\n",
      "Collecting mergedeep>=1.3.4 (from mkdocs->tabpfn==2.0.7)\n",
      "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mkdocs-get-deps>=0.2.0 (from mkdocs->tabpfn==2.0.7)\n",
      "  Downloading mkdocs_get_deps-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting watchdog>=2.0 (from mkdocs->tabpfn==2.0.7)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting babel~=2.10 (from mkdocs-material->tabpfn==2.0.7)\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting backrefs~=5.7.post1 (from mkdocs-material->tabpfn==2.0.7)\n",
      "  Downloading backrefs-5.8-py312-none-any.whl.metadata (3.3 kB)\n",
      "Collecting mkdocs-material-extensions~=1.3 (from mkdocs-material->tabpfn==2.0.7)\n",
      "  Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting paginate~=0.5 (from mkdocs-material->tabpfn==2.0.7)\n",
      "  Downloading paginate-0.5.7-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pygments~=2.16 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from mkdocs-material->tabpfn==2.0.7) (2.19.1)\n",
      "Collecting mkdocstrings-python>=1.16.2 (from mkdocstrings[python]; extra == \"dev\"->tabpfn==2.0.7)\n",
      "  Downloading mkdocstrings_python-1.16.8-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx->tabpfn==2.0.7)\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit->tabpfn==2.0.7)\n",
      "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit->tabpfn==2.0.7)\n",
      "  Downloading identify-2.6.9-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit->tabpfn==2.0.7)\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit->tabpfn==2.0.7)\n",
      "  Downloading virtualenv-20.29.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting iniconfig (from pytest->tabpfn==2.0.7)\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->tabpfn==2.0.7)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting griffe>=1.6.2 (from mkdocstrings-python>=1.16.2->mkdocstrings[python]; extra == \"dev\"->tabpfn==2.0.7)\n",
      "  Downloading griffe-1.7.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->tabpfn==2.0.7) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rayba\\music\\mestrado_dados\\vale-nova\\.venv\\lib\\site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn==2.0.7) (2025.1.31)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->tabpfn==2.0.7)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->mike->tabpfn==2.0.7)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading black-25.1.0-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading mike-2.1.3-py3-none-any.whl (33 kB)\n",
      "Downloading mkdocs-1.6.1-py3-none-any.whl (3.9 MB)\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 2.4/3.9 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.9/3.9 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading mkdocs_autorefs-1.4.1-py3-none-any.whl (5.8 MB)\n",
      "   ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 2.4/5.8 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.7/5.8 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.8/5.8 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading mkdocs_gen_files-0.5.0-py3-none-any.whl (8.4 kB)\n",
      "Downloading mkdocs_glightbox-0.4.0-py3-none-any.whl (31 kB)\n",
      "Downloading mkdocs_literate_nav-0.6.2-py3-none-any.whl (13 kB)\n",
      "Downloading mkdocs_material-9.6.9-py3-none-any.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.4/8.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.0/8.7 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading mypy-1.15.0-cp312-cp312-win_amd64.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.4/9.4 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.4 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/14.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.7/14.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.1/14.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.5 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.8/14.5 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.5 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached pytest-8.3.5-py3-none-any.whl (343 kB)\n",
      "Downloading ruff-0.11.2-py3-none-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.4 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.4 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.2 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading backrefs-5.8-py312-none-any.whl (398 kB)\n",
      "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading ghp_import-2.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading identify-2.6.9-py2.py3-none-any.whl (99 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
      "Downloading mkdocs_get_deps-0.2.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading mkdocs_material_extensions-1.3.1-py3-none-any.whl (8.7 kB)\n",
      "Downloading mkdocstrings_python-1.16.8-py3-none-any.whl (124 kB)\n",
      "Downloading mkdocstrings-0.29.0-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 10.9 MB/s eta 0:00:00\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Downloading paginate-0.5.7-py2.py3-none-any.whl (13 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading pygments_ansi_color-0.3.0-py3-none-any.whl (10 kB)\n",
      "Downloading pymdown_extensions-10.14.3-py3-none-any.whl (264 kB)\n",
      "Downloading pyyaml_env_tag-0.1-py3-none-any.whl (3.9 kB)\n",
      "Downloading virtualenv-20.29.3-py3-none-any.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading markdown_exec-1.10.3-py3-none-any.whl (34 kB)\n",
      "Downloading verspec-0.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading griffe-1.7.0-py3-none-any.whl (129 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Building wheels for collected packages: tabpfn\n",
      "  Building editable for tabpfn (pyproject.toml): started\n",
      "  Building editable for tabpfn (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tabpfn: filename=tabpfn-2.0.7-0.editable-py3-none-any.whl size=14651 sha256=dbb5eb31423844a9f0ba4dc2e60bfcf4f52bbf47134009a5478594026d8a49a4\n",
      "  Stored in directory: C:\\Users\\rayba\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2m_7gjdz\\wheels\\fb\\bc\\4a\\d694dbb653959c10605e39de1cc4fcdd1818e4016e3d5cb73d\n",
      "Successfully built tabpfn\n",
      "Installing collected packages: verspec, paginate, mkdocs-glightbox, distlib, zipp, watchdog, virtualenv, ruff, pyyaml-env-tag, pygments-ansi-color, protobuf, pluggy, pathspec, nodeenv, mypy-extensions, mkdocs-material-extensions, mergedeep, markdown, iniconfig, importlib-resources, identify, griffe, click, cfgv, backrefs, babel, pytest, pymdown-extensions, pre-commit, onnx, mypy, mkdocs-get-deps, importlib-metadata, ghp-import, black, tabpfn, mkdocs, markdown-exec, mkdocs-material, mkdocs-literate-nav, mkdocs-gen-files, mkdocs-autorefs, mike, mkdocstrings, mkdocstrings-python\n",
      "  Attempting uninstall: tabpfn\n",
      "    Found existing installation: tabpfn 2.0.8\n",
      "    Uninstalling tabpfn-2.0.8:\n",
      "      Successfully uninstalled tabpfn-2.0.8\n",
      "Successfully installed babel-2.17.0 backrefs-5.8 black-25.1.0 cfgv-3.4.0 click-8.1.8 distlib-0.3.9 ghp-import-2.1.0 griffe-1.7.0 identify-2.6.9 importlib-metadata-8.6.1 importlib-resources-6.5.2 iniconfig-2.1.0 markdown-3.7 markdown-exec-1.10.3 mergedeep-1.3.4 mike-2.1.3 mkdocs-1.6.1 mkdocs-autorefs-1.4.1 mkdocs-gen-files-0.5.0 mkdocs-get-deps-0.2.0 mkdocs-glightbox-0.4.0 mkdocs-literate-nav-0.6.2 mkdocs-material-9.6.9 mkdocs-material-extensions-1.3.1 mkdocstrings-0.29.0 mkdocstrings-python-1.16.8 mypy-1.15.0 mypy-extensions-1.0.0 nodeenv-1.9.1 onnx-1.17.0 paginate-0.5.7 pathspec-0.12.1 pluggy-1.5.0 pre-commit-4.2.0 protobuf-6.30.2 pygments-ansi-color-0.3.0 pymdown-extensions-10.14.3 pytest-8.3.5 pyyaml-env-tag-0.1 ruff-0.11.2 tabpfn-2.0.7 verspec-0.1.0 virtualenv-20.29.3 watchdog-6.0.0 zipp-3.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tabpfn-extensions 0.1.0 requires numpy<2,>=1.21.0, but you have numpy 2.2.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/PriorLabs/TabPFN.git\n",
    "!pip install -e \"TabPFN[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabpfn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Assuming there is a TabPFNRegressor (if not, a different regressor should be used)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabpfn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TabPFNRegressor  \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load Boston Housing data\u001b[39;00m\n\u001b[32m      9\u001b[39m df = fetch_openml(data_id=\u001b[32m531\u001b[39m, as_frame=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Boston Housing dataset\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tabpfn'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming there is a TabPFNRegressor (if not, a different regressor should be used)\n",
    "from tabpfn import TabPFNRegressor  \n",
    "\n",
    "# Load Boston Housing data\n",
    "df = fetch_openml(data_id=531, as_frame=True)  # Boston Housing dataset\n",
    "X = df.data\n",
    "y = df.target.astype(float)  # Ensure target is float for regression\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize the regressor\n",
    "regressor = TabPFNRegressor()  \n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Modelos\n",
    "from tabpfn import TabPFNRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor  # <-- importando XGBRegressor\n",
    "\n",
    "###############################################################################\n",
    "# 1) Carregar e pré-processar a base\n",
    "###############################################################################\n",
    "caminho_arquivo = \"Flotacao_conceicao_II_all.csv\"\n",
    "df = pd.read_csv(caminho_arquivo, sep=';', low_memory=True)\n",
    "\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%d/%m/%Y %H:%M')\n",
    "df.set_index('Data', inplace=True)\n",
    "\n",
    "# Substituir vírgulas por pontos e converter para float32\n",
    "df = df.replace(',', '.', regex=True).astype(np.float32)\n",
    "\n",
    "df = df.sort_index()  # Garantir ordem cronológica\n",
    "\n",
    "# Exemplos de filtros\n",
    "df = df.mask(df['Vazão de alimentação da flotação (m³/h)'] <= 350)\n",
    "df = df.mask(df['Densid alim flot (t/m³)'] <= 1.3)\n",
    "df = df.dropna()\n",
    "\n",
    "# Remover valores <= 0\n",
    "df = df.mask(df <= 0)\n",
    "df = df.ffill().bfill()\n",
    "\n",
    "target_col = 'SiO2 C flot (%)'\n",
    "\n",
    "# Lista de colunas que NÃO queremos usar como features\n",
    "features_remove = [\n",
    "    '+0,15mm alim flot (%)', 'Fe alim flot (%)', 'Est Esp Cleaner 2 (m/s)',\n",
    "    'SiO2 alim flot  (%)', 'Est Esp Cleaner 1 (m/s)', 'Fe (%)',\n",
    "    'Tem Res Rougher 2 (min)', 'MgO alim flot (%)', 'Tem Res Cleaner 1 (min)',\n",
    "    'Tem Res Re-Cleaner  (min)', 'Tem Res Cleaner 2 (min)',\n",
    "    'Pressão desl 3ª S (kgf/cm²)', '2Cleaner (cm)', 'Est Esp Re-Cleaner (m/s)',\n",
    "    '+0,25mm alim flot (%)', 'SiO2  (%)', '+6,3mm (%)',\n",
    "    'Al2O3 alim flot (%)', 'Densid alim flot (t/m³)',\n",
    "    'Pressão desl 2ª S (kgf/cm²)', 'Fe C flot (%)','SiO2 C flot (%)'\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# 2) Criar lags (defasagens) da coluna-alvo\n",
    "###############################################################################\n",
    "# Exemplo: criar 3 lags (t-1, t-2, t-3)\n",
    "# n_lags = 3\n",
    "# for i in range(1, n_lags + 1):\n",
    "#     df[f'{target_col}_lag{i}'] = df[target_col].shift(i)\n",
    "\n",
    "# Após criar lags, haverá NaN nas primeiras linhas (onde não há valor anterior)\n",
    "df = df.dropna()\n",
    "\n",
    "###############################################################################\n",
    "# 3) Definir X e y (incluindo as colunas de lag)\n",
    "###############################################################################\n",
    "# Agora, 'SiO2 C flot (%)' é a coluna a prever; as colunas lags viram parte de X\n",
    "X = df.drop(columns=features_remove, errors='ignore')  # remove colunas irrelevantes\n",
    "y = df[target_col]\n",
    "\n",
    "###############################################################################\n",
    "# 4) Separar treino e teste (por exemplo, 20% para teste)\n",
    "###############################################################################\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=False\n",
    ")\n",
    "\n",
    "# Padronizar (scaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "###############################################################################\n",
    "# 5) Função de Inductive Conformal Prediction\n",
    "###############################################################################\n",
    "def inductive_conformal_prediction(model, X_train_prop, y_train_prop,\n",
    "                                   X_cal, y_cal, X_test, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Treina o modelo em X_train_prop, y_train_prop.\n",
    "    Calcula o erro no conjunto de calibração (X_cal, y_cal).\n",
    "    Extrai quantil (q_hat).\n",
    "    Faz predição no X_test e gera intervalos [y_pred ± q_hat].\n",
    "    Retorna: (y_pred_test, lower, upper, q_hat, training_time).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_prop, y_train_prop)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Previsões no calibration set\n",
    "    y_cal_pred = model.predict(X_cal)\n",
    "    cal_errors = np.abs(y_cal - y_cal_pred)\n",
    "    n_cal = len(y_cal)\n",
    "\n",
    "    # Cálculo do quantil ajustado => cobertura 1 - alpha\n",
    "    alpha_adj = np.ceil((n_cal + 1) * (1 - alpha)) / n_cal\n",
    "    q_hat = np.quantile(cal_errors, alpha_adj)\n",
    "\n",
    "    # Previsões no teste\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    lower = y_pred_test - q_hat\n",
    "    upper = y_pred_test + q_hat\n",
    "\n",
    "    return y_pred_test, lower, upper, q_hat, training_time\n",
    "\n",
    "###############################################################################\n",
    "# 6) Separar o Train (80%) em ProperTrain e Calib\n",
    "###############################################################################\n",
    "X_train_prop, X_cal, y_train_prop, y_cal = train_test_split(\n",
    "    X_train_full_scaled, y_train_full,\n",
    "    test_size=0.1,  # Ajuste conforme desejar a fração para calibração\n",
    "    random_state=42,\n",
    "    shuffle=False\n",
    ")\n",
    "print(\"Tamanhos:\")\n",
    "print(\"  Proper Train =\", X_train_prop.shape)\n",
    "print(\"  Calib        =\", X_cal.shape)\n",
    "print(\"  Test         =\", X_test_scaled.shape)\n",
    "\n",
    "###############################################################################\n",
    "# 7) (Opcional) Função para limitar tamanho do treinamento TabPFN\n",
    "###############################################################################\n",
    "def limit_training_size(X_data, y_data, max_size=10000):\n",
    "    if len(X_data) > max_size:\n",
    "        return X_data[:max_size], y_data[:max_size]\n",
    "    else:\n",
    "        return X_data, y_data\n",
    "\n",
    "###############################################################################\n",
    "# 8) Definir dicionário de modelos (incluindo XGBRegressor)\n",
    "###############################################################################\n",
    "models = {\n",
    "    \"TabPFN\": TabPFNRegressor(ignore_pretraining_limits=True),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"XGB\": XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 9) Treinar cada modelo e aplicar Conformal\n",
    "###############################################################################\n",
    "alpha = 0.05  # Cobertura de 95%\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "\n",
    "    # Para o TabPFN, limitar se necessário\n",
    "    if model_name == \"TabPFN\":\n",
    "        X_train_prop_used, y_train_prop_used = limit_training_size(X_train_prop, y_train_prop, max_size=10000)\n",
    "    else:\n",
    "        # RandomForest e XGB => usar todo o conjunto\n",
    "        X_train_prop_used, y_train_prop_used = X_train_prop, y_train_prop\n",
    "\n",
    "    y_pred_test, lower_test, upper_test, q_hat, training_time = inductive_conformal_prediction(\n",
    "        model,\n",
    "        X_train_prop_used, y_train_prop_used,\n",
    "        X_cal, y_cal,\n",
    "        X_test_scaled,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "    # Métricas\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"{model_name} => MSE: {mse:.4f} | RMSE: {rmse:.4f} | R2: {r2:.4f} | Tempo treino: {training_time:.2f}s | q_hat={q_hat:.2f}\")\n",
    "\n",
    "    # Cobertura no teste\n",
    "    within_interval = (y_test >= lower_test) & (y_test <= upper_test)\n",
    "    coverage = within_interval.mean()\n",
    "    print(f\"Coverage (95% esperado): {coverage:.3f}\")\n",
    "\n",
    "    # Construir DataFrame de resultado\n",
    "    df_res = pd.DataFrame({\n",
    "        'actual': y_test,\n",
    "        'predicted': y_pred_test,\n",
    "        'lower': lower_test,\n",
    "        'upper': upper_test\n",
    "    }, index=y_test.index)\n",
    "    results[model_name] = df_res\n",
    "\n",
    "###############################################################################\n",
    "# 10) Plotar resultados no teste\n",
    "###############################################################################\n",
    "for model_name, df_res in results.items():\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(df_res.index, df_res['actual'], label='Valor Real', color='blue')\n",
    "    plt.plot(df_res.index, df_res['predicted'], label=f'{model_name}_Pred', color='red')\n",
    "    plt.fill_between(\n",
    "        df_res.index,\n",
    "        df_res['lower'],\n",
    "        df_res['upper'],\n",
    "        color='gray',\n",
    "        alpha=0.2,\n",
    "        label='Conformal Interval'\n",
    "    )\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('SiO2 C flot (%)')\n",
    "    plt.title(f'Conformal Prediction - {model_name} (com lags)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Opcional: salvar CSV de cada modelo\n",
    "for model_name, df_res in results.items():\n",
    "    csv_name = f\"predictions_{model_name}_lags.csv\"\n",
    "    df_res.to_csv(csv_name)\n",
    "    print(f\"Arquivo salvo: {csv_name}\")\n",
    "\n",
    "print(\"\\nPipeline concluído!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
